services:
  ollama:
    image: ollama/ollama:latest
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ollama:/root/.ollama
    ports:
      - "11434:11434"
    runtime: nvidia
    networks:
      - app-network

  open_web_ui:
    image: dyrnq/open-webui
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - open-webui:/app/backend/data
    ports:
      - "3000:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: always
    runtime: nvidia
    networks:
      - app-network

  cloudflared:
    image: cloudflare/cloudflared:latest
    command: tunnel --no-autoupdate run --token ${CLOUDFLARE_TOKEN_INT64_VPC1}
    network_mode: "host"
    environment:
      - CLOUDFLARE_TOKEN=${CLOUDFLARE_TOKEN_INT64_VPC1}
    restart: always
  
  neo4j:
    image: neo4j:latest
    environment:
      - NEO4J_AUTH=neo4j/testpassword
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.meta.data
      - NEO4J_apoc_export_file_enabled=true
      - NEO4JLABS_PLUGINS=["apoc", "n10s"]
    volumes:
      - neo4j_data:/data
    ports:
      - "7687:7687"
      - "7474:7474"
    networks:
      - app-network

networks:
  app-network:
    external: true

volumes:
  ollama:
  open-webui:
  pipelines:
  neo4j_data:
